{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install groq==0.13.1 PyPDF2==3.0.1 pandas==2.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5M0mGmOUk5Y",
        "outputId": "48cbca5a-33a1-4851-a5fc-f4a80f88a985"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq==0.13.1 in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq==0.13.1) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq==0.13.1) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq==0.13.1) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq==0.13.1) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq==0.13.1) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.13.1) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq==0.13.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq==0.13.1) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "Uiom41v7U4CG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from groq import Groq\n"
      ],
      "metadata": {
        "id": "gn_hWL85VwMm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Groq client\n",
        "client = Groq(api_key=GROQ_API_KEY)"
      ],
      "metadata": {
        "id": "8X3NDZmSVqHW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create resumes folder with atleast 10 pdf resume files\n",
        "#you will get ats_resluts.csv in the end.\n",
        "#Install dependencies\n",
        "#!pip install groq python-dotenv PyPDF2 pandas\n",
        "\n",
        "# # Import necessary libraries\n",
        "# import os\n",
        "# import re\n",
        "# import pandas as pd\n",
        "# from PyPDF2 import PdfReader\n",
        "# from groq import Groq\n",
        "# from google.colab import userdata\n",
        "\n",
        "# # Set your Groq API key using Colab's userdata\n",
        "# GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# # Initialize the Groq client with the Colab userdata key\n",
        "# client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "# Function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = \"\"\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() or \"\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading {pdf_path}: {str(e)}\"\n",
        "\n",
        "# Function to extract email, name, and phone number from resume text\n",
        "def extract_email_name_phone(text):\n",
        "    # Extract email using regex\n",
        "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", text)\n",
        "    email = email_match.group() if email_match else \"Not Found\"\n",
        "\n",
        "    # Refined phone number regex (covers more formats and avoids capturing year-like patterns)\n",
        "    phone_match = re.search(r\"(\\+?\\d{1,4}[\\s-]?)?(\\(?\\d{1,3}\\)?[\\s-]?)?(\\d{1,4}[\\s-]?)?(\\d{1,4}[\\s-]?)?(\\d{1,4})\", text)\n",
        "\n",
        "    # Check for valid phone numbers: Filter out years or non-phone-like numbers\n",
        "    phone_number = phone_match.group() if phone_match else \"Not Found\"\n",
        "    if re.match(r\"\\d{4}\", phone_number):  # If it's a 4-digit number (like \"2022\"), consider it invalid\n",
        "        phone_number = \"Not Found\"\n",
        "\n",
        "    # Improved name extraction: Searching for common name patterns or using the first line as fallback\n",
        "    name_match = re.search(r\"(?:Name|Full\\s*Name)[\\s:]*([A-Za-z\\s]+)\", text, re.IGNORECASE)\n",
        "\n",
        "    if name_match:\n",
        "        name = name_match.group(1).strip()\n",
        "    else:\n",
        "        # Attempt to extract the name by considering the first non-empty line\n",
        "        name = next((line.strip() for line in text.splitlines() if line.strip()), \"Name not found\")\n",
        "\n",
        "    return name, email, phone_number\n",
        "\n",
        "# Function to get match score using Groq API\n",
        "def get_match_score(jd, resume_text, model=\"llama3-8b-8192\"):\n",
        "    prompt = f\"\"\"\n",
        "    Job Description: {jd}\n",
        "    Resume: {resume_text}\n",
        "\n",
        "    Please provide:\n",
        "    1. A match score (0-100) between the job description and resume.\n",
        "    2. Missing keywords from the resume based on the job description.\n",
        "    3. A one-sentence summary of the applicant.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            model=model,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Main ATS processing function\n",
        "def process_bulk_resumes(jd, pdf_folder):\n",
        "    results = []\n",
        "    for file in os.listdir(pdf_folder):\n",
        "        if file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, file)\n",
        "            print(f\"Processing {file}...\")\n",
        "\n",
        "            # Extract text, email, name, and phone number\n",
        "            resume_text = extract_text_from_pdf(pdf_path)\n",
        "            name, email, phone_number = extract_email_name_phone(resume_text)\n",
        "\n",
        "            # Get match score and LLM feedback\n",
        "            llm_response = get_match_score(jd, resume_text)\n",
        "            match_score_match = re.search(r\"match score.*?(\\d{1,3})\", llm_response, re.IGNORECASE)\n",
        "            match_score = int(match_score_match.group(1)) if match_score_match else \"N/A\"\n",
        "\n",
        "            # Append to results\n",
        "            results.append({\"Name\": name, \"Email\": email, \"Phone Number\": phone_number, \"Match Score\": match_score})\n",
        "\n",
        "    # Save results to CSV\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(\"ats_results.csv\", index=False)\n",
        "    print(\"Results saved to ats_results.csv\")\n",
        "\n",
        "# Example Usage\n",
        "# Prompt user to input JD (Job Description)\n",
        "jd = input(\"Please enter the Job Description: \")\n",
        "\n",
        "# Upload resumes to Colab folder, set JD, and run\n",
        "pdf_folder = \"/content/resumes\"  # Replace with the path to your resumes folder\n",
        "\n",
        "# Process resumes\n",
        "process_bulk_resumes(jd, pdf_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyc-jGq3aLeu",
        "outputId": "48b4bf0e-678f-4116-b172-08a3a0ca1ed5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the Job Description: Full job description We are a software development company with a strong specialised focus on developing artificial intelligence-based solutions for real-world industrial problems. We focus on using state-of-the-art AI technologies to solve complex industrial problems.  We are looking for a Machine Learning (ML) engineer, with a specialisation in deep learning, to join our team.  Position Details  Type: Full-time  Location: In-person, Johar Town Lahore  Job Description  Coordinating with an in-house or external data team to design a strategy for collecting appropriate data for building a deep learning model for the required task  Designing, building and training deep learning models using state-of-the-art architectures including CNNs, LSTMs, attention networks and transformers. Training is either done on our on-premise servers or on the cloud (e.g., using AWS servers)  Deploying the final model on a server and providing an interface or APIs to interact with it  Minimum Requirements  Bachelor’s or Master’s degree in EE, CS or Data Science  Ability to formulate a problem as a machine learning problem  A reasonable theoretical/mathematical understanding of various deep learning architectures  A reasonable theoretical/mathematical understanding of various objective/loss functions  Strong programming skills in Python  Extensive experience in either TensorFlow or PyTorch  Prior experience of using deep learning either in research or industrial setting  No minimum prior industry experience is needed if the candidate fulfils the above requirements.  Job Type: Full-time  &nbsp;\n",
            "Processing william_harris_resume.pdf...\n",
            "Processing jane_smith_resume.pdf...\n",
            "Processing sarah_white_resume.pdf...\n",
            "Processing john_doe_resume.pdf...\n",
            "Processing Modern Minimalist CV Resume.pdf...\n",
            "Processing emma_taylor_resume.pdf...\n",
            "Processing alex_johnson_resume.pdf...\n",
            "Processing linda_clark_resume.pdf...\n",
            "Processing david_green_resume.pdf...\n",
            "Processing michael_brown_resume.pdf...\n",
            "Results saved to ats_results.csv\n"
          ]
        }
      ]
    }
  ]
}